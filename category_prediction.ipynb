{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "# Category prediction: data preprocessing, visualization and validation\n",
    "<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categories tree processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "categories_path = '/Users/dzendmitry/dev/lab/category_prediction/categories.json'\n",
    "\n",
    "def dive_into_category(objects, arr):\n",
    "    for obj in objects:\n",
    "        arr.append(obj)\n",
    "        if obj[\"child_count\"] > 0:\n",
    "            dive_into_category(obj[\"children\"], arr)\n",
    "            \n",
    "def build_category_arr():\n",
    "    categories_tree = json.load(open(categories_path))\n",
    "    arr = []\n",
    "    dive_into_category(categories_tree, arr)\n",
    "    return arr\n",
    "\n",
    "def get_subtree(categories, name_en):\n",
    "    subtree = []\n",
    "    for category_obj in categories:\n",
    "        if category_obj[\"name_en\"] != name_en:\n",
    "            continue\n",
    "        subtree.append(category_obj)\n",
    "        break\n",
    "    if len(subtree) == 0:\n",
    "        return []\n",
    "    while subtree[-1][\"parent\"] != None:\n",
    "        parent_id = subtree[-1][\"parent\"]\n",
    "        for category_obj in categories:\n",
    "            if category_obj[\"id_catalog_category\"] != parent_id:\n",
    "                continue\n",
    "            subtree.append(category_obj)\n",
    "            break\n",
    "    return subtree\n",
    "        \n",
    "def get_category_lvl(categories, name_en, level):\n",
    "    subtree = get_subtree(categories, name_en)\n",
    "    if len(subtree) == 0:\n",
    "        return []\n",
    "    if level >= len(subtree):\n",
    "        return subtree[0]\n",
    "    return subtree[-level]\n",
    "\n",
    "categories_arr = build_category_arr()\n",
    "\n",
    "# map: category -> color\n",
    "naive_categories = dict()\n",
    "\n",
    "def get_category(categories, max_color):\n",
    "    target_category = \"none\"\n",
    "    ncs = categories.split('|')\n",
    "    for nc in ncs:\n",
    "        c = get_category_lvl(categories_arr, nc, 1)\n",
    "        if len(c) == 0:\n",
    "            continue\n",
    "        target_category = c[\"name_en\"]\n",
    "        break\n",
    "    if target_category != \"none\" and target_category not in naive_categories:\n",
    "        naive_categories[target_category] = max_color\n",
    "        max_color += 1\n",
    "    return (target_category, max_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelFile = '/Users/dzendmitry/dev/lab/category_prediction/fasttext_models/model_wiki_en/model.bin'\n",
    "modelFile = '/Users/dzendmitry/dev/lab/category_prediction/fasttext_models/model_full_cbow_minn3_maxn10_wordNgrams2_lr0.5_dim100_ws3/model.bin'\n",
    "#modelFile = '/Users/dzendmitry/dev/lab/category_prediction/fasttext_models/model_full_skipgram_minn3_maxn10_wordNgrams2_lr0.5_dim100_ws3/model.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastText\n",
    "model = fastText.load_model(modelFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular expressions for data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "extra_symbols_pattern = re.compile(r\"[^A-Za-z0-9\\s]\")\n",
    "small_phrases_pattern = re.compile(r\"\\s\\S{,2}\\s\")\n",
    "extra_spaces_pattern  = re.compile(r'\\s{2,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data with category unification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inFile    = '/Users/dzendmitry/dev/lab/category_prediction/10000.csv'\n",
    "outFile   = '/Users/dzendmitry/dev/lab/category_prediction/10000_out.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(outFile, \"w\", newline='') as wfile:\n",
    "    wtr = csv.writer(wfile)\n",
    "    with open(inFile, newline='') as rfile:\n",
    "        rdr = csv.reader(rfile, delimiter=',', quotechar='\"')\n",
    "        i = 1\n",
    "        for row in rdr:\n",
    "            if len(row) < 2:\n",
    "                continue\n",
    "            categories = row[1].split('|')\n",
    "            sentence = ' '.join(row[0].splitlines())\n",
    "            sv = model.get_sentence_vector(sentence) # category unification\n",
    "            sentence = re.sub(extra_symbols_pattern, \"\", sentence)\n",
    "            sentence = re.sub(small_phrases_pattern, \"\", sentence)\n",
    "            sentence = re.sub(extra_spaces_pattern, \" \", sentence)\n",
    "            sentence = sentence.lower()\n",
    "            wtr.writerow((sentence, sv, '|'.join(sorted(categories, key=str.lower))))\n",
    "            if i % 100000 == 0:\n",
    "                print(\"done: \", i)\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation datasets from preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "X = list()\n",
    "Y = list()\n",
    "colors = list()\n",
    "Y_num = list()\n",
    "\n",
    "with open(outFile, newline='') as rfile:\n",
    "    rdr = csv.reader(rfile, delimiter=',', quotechar='\"')\n",
    "    max_color = 1\n",
    "    for row in rdr:\n",
    "        v = np.fromstring(row[1][1:-1], dtype=np.float64, sep=' ')\n",
    "        (category, max_color) = get_category(row[2], max_color)\n",
    "        if category == \"none\":\n",
    "            continue\n",
    "        X.append(v)\n",
    "        Y.append(category)\n",
    "        colors.append(naive_categories[category])\n",
    "    X = np.asarray(X)\n",
    "    colors = np.asarray(colors)\n",
    "    Y_num = colors.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X:\", X.shape, \"Y:\", len(Y), \"colors:\", colors.shape, \"naive_categories:\", len(naive_categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation centers of masses from raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mass_centers_df = pd.DataFrame(data=X, \n",
    "             columns=[i for i in range(X.shape[1])])\n",
    "mass_centers_df['text_class'] = Y\n",
    "mass_centers_gb = mass_centers_df.groupby('text_class')\n",
    "mass_centers = mass_centers_gb.sum()\n",
    "mass_center_counts = mass_centers_gb.size()\n",
    "print('mass_centers:', mass_centers.shape, 'mass_center_counts:', mass_center_counts.shape)\n",
    "for i in range(len(mass_center_counts)):\n",
    "    mass_centers.iloc[i] /= mass_center_counts.iloc[i]\n",
    "print(\"mass_centers result:\", mass_centers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_labels = list()\n",
    "gb_colors = list()\n",
    "for label, data in mass_centers_gb:\n",
    "    gb_labels.append(label)\n",
    "    gb_colors.append(naive_categories[label])\n",
    "print('gb_colors:', len(gb_colors), 'gb_labels:', len(gb_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA [ principal component analysis ] - for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "pca_X_obj = decomposition.PCA(n_components=3)\n",
    "pca_X_obj.fit(X)\n",
    "pca_X = pca_X_obj.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pca_X_df = pd.DataFrame(data=pca_X, \n",
    "             columns=['X', 'Y', 'Z'])\n",
    "pca_X_df['class'] = colors\n",
    "pca_X_df['text_class'] = Y\n",
    "pca_X_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation centers of masses from PCA-processed data for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pca_X_gb = pca_X_df.groupby('text_class')\n",
    "pca_X_mass_centers = pca_X_gb.sum()\n",
    "pca_X_mass_centers_size = pca_X_gb.size()\n",
    "print('pca_X_mass_centers:', pca_X_mass_centers.shape, 'pca_X_size:', pca_X_mass_centers_size.shape)\n",
    "for i in range(len(pca_X_mass_centers_size)):\n",
    "    pca_X_mass_centers.iloc[i] /= pca_X_mass_centers_size.iloc[i]\n",
    "print(\"pca_X_mass_centers result:\", pca_X_mass_centers.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot titles in category classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "from plotly.graph_objs import Scatter, Layout\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "import random\n",
    "random.seed()\n",
    "\n",
    "colormap=dict()\n",
    "for label, index in naive_categories.items():\n",
    "    r = random.randint(0, 255)\n",
    "    g = random.randint(0, 255)\n",
    "    b = random.randint(0, 255)\n",
    "    color_text = 'rgb({0}, {1}, {2})'.format(r, g, b)\n",
    "    colormap[label] = color_text\n",
    "\n",
    "traces = []\n",
    "for label, data in pca_X_df.groupby('text_class'):\n",
    "    trace = go.Scatter3d(\n",
    "        name=label,\n",
    "        x=data['X'],\n",
    "        y=data['Y'],\n",
    "        z=data['Z'],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=5,\n",
    "            color=colormap[label],\n",
    "            line=dict(\n",
    "                color=colormap[label],\n",
    "                width=0.1\n",
    "            ),\n",
    "            opacity=0.2\n",
    "        )\n",
    "    )\n",
    "    traces.append(trace)\n",
    "    \n",
    "for index, data in pca_X_mass_centers.iterrows():\n",
    "    label = data.name\n",
    "    trace = go.Scatter3d(\n",
    "        name=\"MC === \"+label,\n",
    "        x=[data['X']],\n",
    "        y=[data['Y']],\n",
    "        z=[data['Z']],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=8,\n",
    "            color=colormap[label],\n",
    "        line=dict(\n",
    "            color=colormap[label],\n",
    "            width=0.1\n",
    "        ),\n",
    "        opacity=0\n",
    "        )\n",
    "    )\n",
    "    traces.append(trace)\n",
    "\n",
    "layout = go.Layout(\n",
    "    margin=dict(\n",
    "        l=0,\n",
    "        r=0,\n",
    "        b=0,\n",
    "        t=0\n",
    "    ),\n",
    "    legend=dict(x=-.1, y=1.2)\n",
    ")\n",
    "\n",
    "plotly.offline.iplot({\n",
    "    \"data\": traces,\n",
    "    \"layout\": layout\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data for cbow and skipgram models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inFileTrain  = '/Users/dzendmitry/dev/lab/category_prediction/10000.csv'\n",
    "outFileTrain = '/Users/dzendmitry/dev/lab/category_prediction/10000_train.csv'\n",
    "\n",
    "with open(outFileTrain, \"w\", newline='') as wfile:\n",
    "    with open(inFileTrain, newline='') as rfile:\n",
    "        rdr = csv.reader(rfile, delimiter=',', quotechar='\"')\n",
    "        i = 1\n",
    "        for row in rdr:\n",
    "            if len(row) < 2:\n",
    "                continue\n",
    "            title = re.sub(extra_symbols_pattern, \"\", row[0])\n",
    "            title = re.sub(small_phrases_pattern, \"\", title)\n",
    "            title = re.sub(extra_spaces_pattern, \" \", title)\n",
    "            title = title.lower()\n",
    "            description = re.sub(extra_symbols_pattern, \"\", row[2])\n",
    "            description = re.sub(small_phrases_pattern, \"\", description)\n",
    "            description = re.sub(extra_spaces_pattern, \" \", description)\n",
    "            description = description.lower()\n",
    "            wfile.write(title + \" \" + description)\n",
    "            if i % 100000 == 0:\n",
    "                print(\"done: \", i)\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation words frequency and words frequencies in categories for statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import csv\n",
    "\n",
    "#import time\n",
    "#def current_milli_time():\n",
    "#    return int(round(time.time() * 1000))\n",
    "#start_time = current_milli_time()\n",
    "#time_diff = current_milli_time() - start_time\n",
    "#print(\"get_category time: \", time_diff)\n",
    "\n",
    "inStatisticsFile = '/Users/dzendmitry/dev/lab/category_prediction/10000.csv'\n",
    "\n",
    "wsDict = dict()\n",
    "\n",
    "with open(inStatisticsFile, newline='') as rfile:\n",
    "    rdr = csv.reader(rfile, delimiter=',', quotechar='\"')\n",
    "    i = 1\n",
    "    max_color = 1\n",
    "    \n",
    "    for row in rdr:\n",
    "        if len(row) < 3:\n",
    "            continue\n",
    "            \n",
    "        if len(row[0]) == 0:\n",
    "            continue\n",
    "        \n",
    "        (category, max_color) = get_category(row[1], max_color)\n",
    "        if category == \"none\":\n",
    "            continue\n",
    "            \n",
    "        sentence = ' '.join(row[0].splitlines())\n",
    "        sentence = re.sub(extra_symbols_pattern, \"\", sentence)\n",
    "        sentence = re.sub(small_phrases_pattern, \"\", sentence)\n",
    "        sentence = re.sub(extra_spaces_pattern, \" \", sentence)\n",
    "        sentence = sentence.lower()\n",
    "        \n",
    "        if len(sentence) == 0:\n",
    "            continue\n",
    "            \n",
    "        words = sentence.split()\n",
    "        try:\n",
    "            for word in words:\n",
    "                cDict = wsDict.get(word)\n",
    "                if cDict == None:\n",
    "                    wsDict[word] = dict()\n",
    "                    cDict = wsDict[word]\n",
    "                if cDict.get(category) == None:\n",
    "                    cDict[category] = 1\n",
    "                else:\n",
    "                    cDict[category] += 1\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(sentence)\n",
    "            print(words)\n",
    "            break\n",
    "        \n",
    "        if i % 100000 == 0:\n",
    "            print(\"done: \", i)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#def save_obj(obj, name):\n",
    "#    with open('obj/'+ name + '.pkl', 'wb') as f:\n",
    "#        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_obj(wsDict, 'data_classes_distributions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "wordStatistics = pd.DataFrame(wsDict).transpose()\n",
    "wordStatistics = wordStatistics.fillna(0)\n",
    "ws = wordStatistics\n",
    "wordStatistics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws['count_all'] = ws.sum(axis=1, numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_sorted = ws.sort_values(by=['count_all'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ws_sorted.to_csv('obj/data_classes_distributions_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "data = [go.Bar(\n",
    "    x=ws_sorted.index[:1000],\n",
    "    y=ws_sorted['count_all'][:1000]\n",
    ")]\n",
    "\n",
    "plotly.offline.iplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_sorted.loc['storage'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "data = [go.Bar(\n",
    "    x=ws_sorted.loc['fashion'].index,\n",
    "    y=ws_sorted.loc['fashion']\n",
    ")]\n",
    "\n",
    "plotly.offline.iplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation procedure (The Euclidean metric between mass centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import merge\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "\n",
    "def calc_cartesian_matrix(mass_centers):\n",
    "    \n",
    "    def set_zeroes_below_digonal(m):\n",
    "        dimx, dimy = m.shape\n",
    "        for i in range(dimx):\n",
    "            for j in range(dimy):\n",
    "                if j < i:\n",
    "                    m[i, j] = 0\n",
    "                else:\n",
    "                    break\n",
    "        return m\n",
    "    \n",
    "    merge_matrix = mass_centers.copy()\n",
    "    merge_matrix['key'] = 1\n",
    "    merge_matrix = merge(merge_matrix, merge_matrix, on=['key'])\n",
    "    merge_matrix = merge_matrix.drop(columns=['key'])\n",
    "    x = merge_matrix.iloc[:, :int(merge_matrix.shape[1]/2)].as_matrix()\n",
    "    y = merge_matrix.iloc[:, int(merge_matrix.shape[1]/2):].as_matrix()\n",
    "    cartesian_matrix = np.reshape(np.sqrt(((x - y) ** 2).sum(axis=1)), (mass_centers.shape[0], mass_centers.shape[0]))\n",
    "    return set_zeroes_below_digonal(cartesian_matrix)\n",
    "\n",
    "def draw_matrix(m):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.set_aspect('equal')\n",
    "    plt.imshow(m, interpolation='nearest', cmap=plt.cm.ocean)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "def matrix_to_df_table(m):\n",
    "    pd.set_option(\"display.max_columns\",23)\n",
    "    return pd.DataFrame(data=m, columns=[i for i in range(1, m.shape[1]+1)]).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wiki en model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_centers_wiki_en = mass_centers.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cartesian_matrix_wiki_en = calc_cartesian_matrix(mass_centers_wiki_en)\n",
    "draw_matrix(cartesian_matrix_wiki_en)\n",
    "matrix_to_df_table(cartesian_matrix_wiki_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cbow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_centers_cbow = mass_centers.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cartesian_matrix_cbow = calc_cartesian_matrix(mass_centers_cbow)\n",
    "draw_matrix(cartesian_matrix_cbow)\n",
    "matrix_to_df_table(cartesian_matrix_cbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### skipgram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_centers_skipgram = mass_centers.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cartesian_matrix_skipgram = calc_cartesian_matrix(mass_centers_skipgram)\n",
    "draw_matrix(cartesian_matrix_skipgram)\n",
    "matrix_to_df_table(cartesian_matrix_skipgram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### models diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = cartesian_matrix_wiki_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = cartesian_matrix_cbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cartesian_matrix_diff = model_2 - model_1\n",
    "draw_matrix(cartesian_matrix_diff)\n",
    "matrix_to_df_table(cartesian_matrix_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y_num, test_size=0.2, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#clf = SVC(kernel='linear', C=30.0)\n",
    "clf = SVC(kernel='poly', C=100.0, gamma=0.9, coef0=0.1, degree=3) # 0.8048\n",
    "#clf = SVC(kernel='sigmoid', C=10.0, gamma=0.9, coef0=0.1)\n",
    "start = time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Linear SVM\", end - start, clf.score(X_test, y_test))\n",
    "y_predicted = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "start = time.time()\n",
    "#svm = SVC(kernel='linear', probability=True)\n",
    "clf = BaggingClassifier(n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Bagging SVC\", end - start, clf.score(X_test, y_test))\n",
    "y_predicted = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "def get_metrics(y_test, y_predicted):  \n",
    "    # true positives / (true positives+false positives)\n",
    "    precision = precision_score(y_test, y_predicted, pos_label=None,\n",
    "                                    average='weighted')             \n",
    "    # true positives / (true positives + false negatives)\n",
    "    recall = recall_score(y_test, y_predicted, pos_label=None,\n",
    "                              average='weighted')\n",
    "    \n",
    "    # harmonic mean of precision and recall\n",
    "    f1 = f1_score(y_test, y_predicted, pos_label=None, average='weighted')\n",
    "    \n",
    "    # true positives + true negatives/ total\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "accuracy, precision, recall, f1 = get_metrics(y_test, y_predicted)\n",
    "print(\"accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
